{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Proyecto AA prueba RandomForest LogistalRegression ",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeaBo8GXBlVL"
      },
      "source": [
        "import pandas as pd \n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np\n",
        "\n",
        "urlTrain  = 'https://raw.githubusercontent.com/CyberJuan55/Proyecto-IA/master/DataSet/SpotifyFeatures_train.csv'\n",
        "urlFull = 'https://raw.githubusercontent.com/CyberJuan55/Proyecto-IA/master/DataSet/SpotifyFeatures.csv'\n",
        "# el train que nos dieron los profes\n",
        "#df_train_original= pd.read_csv('/content/SpotifyFeatures_train.csv')\n",
        "df_train_original = pd.read_csv(urlTrain)\n",
        "df_train = df_train_original.copy()\n",
        "# el dataset nuestro\n",
        "df_full_original = pd.read_csv(urlFull)\n",
        "df_full = df_full_original.copy()\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxZcTtP-pqcw"
      },
      "source": [
        "# Exploracion de datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGjNp6rYM6pj",
        "outputId": "9acde1ac-b08b-4f1e-cea4-9658ccb606b5"
      },
      "source": [
        "df_train.dtypes"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unnamed: 0            int64\n",
              "genre                object\n",
              "artist_name          object\n",
              "track_name           object\n",
              "track_id             object\n",
              "popularity            int64\n",
              "acousticness        float64\n",
              "danceability        float64\n",
              "duration_ms           int64\n",
              "energy              float64\n",
              "instrumentalness    float64\n",
              "key                  object\n",
              "liveness            float64\n",
              "loudness            float64\n",
              "mode                 object\n",
              "speechiness         float64\n",
              "tempo               float64\n",
              "time_signature       object\n",
              "valence             float64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWQWUPdoPaA1",
        "outputId": "f05cb3cc-3f79-4eae-84b3-8a6f247c6eef"
      },
      "source": [
        "df_train['genre'].value_counts()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Comedy              7771\n",
              "Soundtrack          7758\n",
              "Jazz                7634\n",
              "Indie               7603\n",
              "Children’s Music    7554\n",
              "Pop                 7532\n",
              "Electronic          7500\n",
              "Rock                7455\n",
              "Hip-Hop             7422\n",
              "Folk                7406\n",
              "Classical           7395\n",
              "Rap                 7367\n",
              "Alternative         7342\n",
              "Soul                7280\n",
              "R&B                 7242\n",
              "World               7211\n",
              "Blues               7187\n",
              "Ska                 7154\n",
              "Reggaeton           7139\n",
              "Anime               7131\n",
              "Reggae              7019\n",
              "Dance               6950\n",
              "Country             6861\n",
              "Opera               6612\n",
              "Movie               6261\n",
              "Children's Music    4298\n",
              "A Capella             96\n",
              "Name: genre, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8w7J-PD07Ta"
      },
      "source": [
        "Vemos que la columna Children esta repetida"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5g24ZZ2Fp4z3"
      },
      "source": [
        "# Variables Categoricas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3Gtfp0WYW1z",
        "outputId": "0391ea0e-d5e6-4149-99cc-080bd4c0fd3d"
      },
      "source": [
        "# Variable categoricas\n",
        "s = (df_train.dtypes == 'object')\n",
        "object_cols = list(s[s].index)\n",
        "print(object_cols)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['genre', 'artist_name', 'track_name', 'track_id', 'key', 'mode', 'time_signature']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QN7ulp0qeaP5",
        "outputId": "daac9d1a-5d87-4778-c591-1bd85b1a05a4"
      },
      "source": [
        "list_of_timeSignature = df_train['time_signature'].unique()\n",
        "print(list_of_timeSignature)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['4/4' '3/4' '5/4' '1/4' '0/4']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "um0qDvtk_kxR",
        "outputId": "913bb840-8cdf-4a17-8b8e-af0726954ee3"
      },
      "source": [
        "df_train['time_signature'].value_counts()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4/4    160645\n",
              "3/4     19247\n",
              "5/4      4198\n",
              "1/4      2083\n",
              "0/4         7\n",
              "Name: time_signature, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXPjOo6k-piY"
      },
      "source": [
        "Decidimos no utilizar Time_signature como feature por varios motivos\n",
        "\n",
        "\n",
        "*   En musica no existe compaces de 1/4 ni de 0/4 entre ambos suman 1656 valores lo que nos parecio un numero considerable\n",
        "*   En una cancion puede haber multiples cambios de compaces, en la musica progresiva es algo muy comun\n",
        "\n",
        "*   La mayoria de la musica se encuentra en 4/4 podemos ver que hay 156851 valores que considerablemente mayor a lo suma de todas las otras categorias esto introduceria un gran sesgo en nuestro modelo \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GH_RGyjwUOnM",
        "outputId": "b127fac7-b564-4098-c561-7738b510a1c9"
      },
      "source": [
        "# variables categoricas con baja cardinalidad\n",
        "categorical_cols = [cname for cname in df_train.columns if\n",
        "                    df_train[cname].nunique() < 14 and \n",
        "                    df_train[cname].dtype == \"object\"]\n",
        "print(categorical_cols)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['key', 'mode', 'time_signature']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poCNhlTChmjj"
      },
      "source": [
        "Quedan descartadas las variables categoricas: \n",
        "\n",
        "*   Time_signature por los motivos comentados anteriormente\n",
        "*   track_id: no hay ninguna razon para utilizarla\n",
        "*   el nombre del artista: son demasiadas variables de momento las sacamos pero es cierto que es un feature interesente \n",
        "*   track_name: todos sus valores son distintos \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQ4BfBobeR_6",
        "outputId": "b2b7561a-0191-4d4a-8603-f3689f5765af"
      },
      "source": [
        "list_of_modes = df_train['mode'].unique()\n",
        "print(list_of_modes)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Major' 'Minor']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YaFNClZWVad",
        "outputId": "b932e508-9a59-4ff2-fc15-dcd7a242c8cf"
      },
      "source": [
        "list_of_keys = df_train['key'].unique()\n",
        "print(list_of_keys)\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['B' 'A#' 'C#' 'C' 'F#' 'E' 'A' 'D' 'G' 'F' 'G#' 'D#']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoEJIv4hqDe1"
      },
      "source": [
        "### Preprocesado de datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7o6tPneUaeji"
      },
      "source": [
        "# Funcion para el preprocesamiento de datos\n",
        "\n",
        "\n",
        "def preprocesado(df):\n",
        "\n",
        "    \n",
        "\n",
        "    if df.duplicated().sum() == 0:\n",
        "        print('no hay datos duplicados')\n",
        "    else:\n",
        "        df.drop_duplicates\n",
        "\n",
        "\n",
        "    if 'Unnamed: 0' in df.columns:\n",
        "        df = df.drop(['Unnamed: 0'], axis=1)\n",
        "    else:\n",
        "        print('no esta')  \n",
        "    df = df.drop_duplicates(subset=['track_name','artist_name'],keep=False)\n",
        "    df = df.drop(['time_signature','track_id','artist_name','track_name'], axis=1)\n",
        "    df['genre']= df['genre'].replace([\"Children’s Music\"],\"Children's Music\")\n",
        "    indexNamesChildren = df[ df['genre'] == \"Children's Music\" ].index\n",
        "    df.drop(indexNamesChildren , inplace=True)\n",
        "    \n",
        "    cols_with_missing = [col for col in df.columns if df[col].isnull().any()] \n",
        "    faltanDatos = True\n",
        "    if len(cols_with_missing)==0:\n",
        "        faltanDatos= False\n",
        "        print('no faltan valores') \n",
        "    if faltanDatos == True:\n",
        "        print(cols_with_missing)\n",
        "        df.dropna(axis=0, inplace=True)\n",
        "\n",
        "    X = df.drop(columns=['genre'])\n",
        "    y = df['genre']\n",
        "    \n",
        "\n",
        "    return X,y \n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bz1kZMM683DZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee6d1ffd-9ca4-4430-c061-c245a13a427e"
      },
      "source": [
        "df_train,y = preprocesado(df_train)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no hay datos duplicados\n",
            "no faltan valores\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hgeZxtHgGVx"
      },
      "source": [
        "df_train_num = df_train.drop([\"key\",'mode'], axis=1)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwlGFXS4fIho"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "num_pipeline = Pipeline([\n",
        "        ('std_scaler', StandardScaler()),\n",
        "    ])\n",
        "cat_attribs1 = [\"key\"]\n",
        "cat_attribs2 = [\"mode\"]\n",
        "num_attribs = list(df_train_num)\n",
        "\n",
        "full_pipeline = ColumnTransformer([\n",
        "        ('numerical', num_pipeline, num_attribs),                          \n",
        "        (\"cat\", OneHotEncoder(drop='first'), cat_attribs1),\n",
        "        (\"cat1\", OrdinalEncoder(), cat_attribs2)\n",
        "    ])\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMcA7Eswgwlz"
      },
      "source": [
        "df_train_processed = full_pipeline.fit_transform(df_train)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHMElHKWg04A"
      },
      "source": [
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_val_predict\n",
        "X_train_full, X_valid_full, y_train, y_valid = train_test_split(df_train_processed, y, \n",
        "                                                                train_size=0.8, test_size=0.2,\n",
        "                                                                random_state=42)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rCDk9Uftbwm",
        "outputId": "5f5f27b0-78d9-4d5c-ecfa-565a1ae66bb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "lg=LogisticRegression(max_iter=2000, random_state=1, penalty = 'l2', C = 0.01) #onevsrestclassifier\n",
        "lg.fit(X_train_full, y_train)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=2000,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=1, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JVONP_Etupl"
      },
      "source": [
        "y_train_pred = lg.predict(X_valid_full)\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlJYWNJbuQiI",
        "outputId": "f6bbc03e-f6ad-4a5a-fcc8-581747f1eb85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "print(accuracy_score(y_valid, y_train_pred))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4665081081081081\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfR6kH-iyHTy",
        "outputId": "5a1f8bd0-7a5b-49ca-bcd4-80a7dddee548",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rfc = RandomForestClassifier(n_estimators=30, random_state=42)\n",
        "rfc.fit(X_train_full, y_train)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=30,\n",
              "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5Vfk2rDyLEG",
        "outputId": "8d36eaa2-98eb-40fb-d463-2c922c52d673",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "predict = rfc.predict(X_valid_full)\n",
        "print(accuracy_score(y_valid, predict))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5494054054054054\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6VcYyvCyrav"
      },
      "source": [
        "# Numero de arboles\n",
        "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 80, num = 8)]\n",
        "# Numero de features considerado al dividir\n",
        "max_features = ['auto', 'sqrt']\n",
        "# numero maximo de niveles\n",
        "max_depth = [2,4]\n",
        "# Numero minimo de niveles por nodo\n",
        "min_samples_split = [2, 5]\n",
        "# Numero minimo de niveles por hoja\n",
        "min_samples_leaf = [1, 2]\n",
        "# metodo de seleccion por arbol \n",
        "bootstrap = [True, False]"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzzuxD9sy2uz",
        "outputId": "6ef1e052-32bc-42a4-8541-73d6c22c128f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(n_estimators)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10, 20, 30, 40, 50, 60, 70, 80]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wh1crlC3yuHh"
      },
      "source": [
        "# Grilla\n",
        "param_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nDRxeJcyw7l"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "rfc_Grid = GridSearchCV(estimator = rfc, param_grid = param_grid, cv = 3, verbose=2, n_jobs = 4)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2G0dUgZyzVy",
        "outputId": "d4bb468e-5dd8-46b6-e5b2-a7df33d34fa7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "rfc_Grid.fit(X_train_full, y_train)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 256 candidates, totalling 768 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:   47.8s\n",
            "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:  4.0min\n"
          ]
        }
      ]
    }
  ]
}