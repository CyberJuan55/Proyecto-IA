{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Proyecto AA prueba RandomForest LogistalRegression ",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeaBo8GXBlVL"
      },
      "source": [
        "import pandas as pd \n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier \n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "urlTrain  = 'https://raw.githubusercontent.com/CyberJuan55/Proyecto-IA/master/DataSet/SpotifyFeatures_train.csv'\n",
        "urlFull = 'https://raw.githubusercontent.com/CyberJuan55/Proyecto-IA/master/DataSet/SpotifyFeatures.csv'\n",
        "# el train que nos dieron los profes\n",
        "#df_train_original= pd.read_csv('/content/SpotifyFeatures_train.csv')\n",
        "df_train_original = pd.read_csv(urlTrain)\n",
        "df_train = df_train_original.copy()\n",
        "# el dataset nuestro\n",
        "df_full_original = pd.read_csv(urlFull)\n",
        "df_full = df_full_original.copy()\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoEJIv4hqDe1"
      },
      "source": [
        "### Preprocesado de datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7o6tPneUaeji"
      },
      "source": [
        "# Funcion para el preprocesamiento de datos\n",
        "\n",
        "\n",
        "def preprocesado(df):\n",
        "\n",
        "    \n",
        "\n",
        "    if df.duplicated().sum() == 0:\n",
        "        print('no hay datos duplicados')\n",
        "    else:\n",
        "        df.drop_duplicates\n",
        "\n",
        "\n",
        "    if 'Unnamed: 0' in df.columns:\n",
        "        df = df.drop(['Unnamed: 0'], axis=1)\n",
        "    else:\n",
        "        print('no esta')  \n",
        "    df = df.drop_duplicates(subset=['track_name','artist_name'],keep=False)\n",
        "    df = df.drop(['time_signature','track_id','artist_name','track_name'], axis=1)\n",
        "    df['genre']= df['genre'].replace([\"Childrenâ€™s Music\"],\"Children's Music\")\n",
        "    indexNamesChildren = df[ df['genre'] == \"Children's Music\" ].index\n",
        "    df.drop(indexNamesChildren , inplace=True)\n",
        "    \n",
        "    cols_with_missing = [col for col in df.columns if df[col].isnull().any()] \n",
        "    faltanDatos = True\n",
        "    if len(cols_with_missing)==0:\n",
        "        faltanDatos= False\n",
        "        print('no faltan valores') \n",
        "    if faltanDatos == True:\n",
        "        print(cols_with_missing)\n",
        "        df.dropna(axis=0, inplace=True)\n",
        "\n",
        "    X = df.drop(columns=['genre'])\n",
        "    y = df['genre']\n",
        "    \n",
        "\n",
        "    return X,y \n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bz1kZMM683DZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bb212d0-962d-4410-8dbe-94d81609f8be"
      },
      "source": [
        "df_train,y = preprocesado(df_train)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no hay datos duplicados\n",
            "no faltan valores\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHMElHKWg04A"
      },
      "source": [
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_val_predict\n",
        "X_train_full, X_valid_full, y_train, y_valid = train_test_split(df_train, y, \n",
        "                                                                train_size=0.8, test_size=0.2,\n",
        "                                                                random_state=42)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hgeZxtHgGVx"
      },
      "source": [
        "df_train_num = X_train_full.drop([\"key\",'mode'], axis=1)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwlGFXS4fIho"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "num_pipeline = Pipeline([\n",
        "        ('std_scaler', StandardScaler()),\n",
        "    ])\n",
        "cat_attribs1 = [\"key\"]\n",
        "cat_attribs2 = [\"mode\"]\n",
        "num_attribs = list(df_train_num)\n",
        "\n",
        "full_pipeline = ColumnTransformer([\n",
        "        ('numerical', num_pipeline, num_attribs),                          \n",
        "        (\"cat\", OneHotEncoder(drop='first'), cat_attribs1),\n",
        "        (\"cat1\", OrdinalEncoder(), cat_attribs2)\n",
        "    ])\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMcA7Eswgwlz"
      },
      "source": [
        "#df_train_processed = full_pipeline.fit_transform(df_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rCDk9Uftbwm"
      },
      "source": [
        "lg=LogisticRegression(max_iter=2000, random_state=1, penalty = 'l2', C = 0.01) #onevsrestclassifier"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovxPLYLNlf4S",
        "outputId": "38ea8351-72cb-432c-fe1a-cdc1fccdd50f"
      },
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "LGpipe = make_pipeline(full_pipeline,lg)\n",
        "LGpipe.fit(X_train_full,y_train)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('columntransformer',\n",
              "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
              "                                   sparse_threshold=0.3,\n",
              "                                   transformer_weights=None,\n",
              "                                   transformers=[('numerical',\n",
              "                                                  Pipeline(memory=None,\n",
              "                                                           steps=[('std_scaler',\n",
              "                                                                   StandardScaler(copy=True,\n",
              "                                                                                  with_mean=True,\n",
              "                                                                                  with_std=True))],\n",
              "                                                           verbose=False),\n",
              "                                                  ['popularity', 'acousticness',\n",
              "                                                   'danceability',\n",
              "                                                   'duration_ms', 'energy',...\n",
              "                                                  OrdinalEncoder(categories='auto',\n",
              "                                                                 dtype=<class 'numpy.float64'>),\n",
              "                                                  ['mode'])],\n",
              "                                   verbose=False)),\n",
              "                ('logisticregression',\n",
              "                 LogisticRegression(C=0.01, class_weight=None, dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    l1_ratio=None, max_iter=2000,\n",
              "                                    multi_class='auto', n_jobs=None,\n",
              "                                    penalty='l2', random_state=1,\n",
              "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                    warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIR2lbPpn8ao"
      },
      "source": [
        "lg_cross_val = cross_val_score(LGpipe,X_train_full,y_train,cv=5,scoring='accuracy').mean()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPZOsxWCrzmM"
      },
      "source": [
        "params = {}\n",
        "\n",
        "params['logisticregression__C'] = [0.1,1,10]\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEC9so6Assb7",
        "outputId": "c8aab646-219a-40c8-e700-edfc9dae0fa2"
      },
      "source": [
        "lGgrid = GridSearchCV(LGpipe, params, cv=5,scoring='accuracy' )\n",
        "lGgrid.fit(X_train_full,y_train)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('columntransformer',\n",
              "                                        ColumnTransformer(n_jobs=None,\n",
              "                                                          remainder='drop',\n",
              "                                                          sparse_threshold=0.3,\n",
              "                                                          transformer_weights=None,\n",
              "                                                          transformers=[('numerical',\n",
              "                                                                         Pipeline(memory=None,\n",
              "                                                                                  steps=[('std_scaler',\n",
              "                                                                                          StandardScaler(copy=True,\n",
              "                                                                                                         with_mean=True,\n",
              "                                                                                                         with_std=True))],\n",
              "                                                                                  verbose=False),\n",
              "                                                                         ['popularity',\n",
              "                                                                          'acoustic...\n",
              "                                                           fit_intercept=True,\n",
              "                                                           intercept_scaling=1,\n",
              "                                                           l1_ratio=None,\n",
              "                                                           max_iter=2000,\n",
              "                                                           multi_class='auto',\n",
              "                                                           n_jobs=None,\n",
              "                                                           penalty='l2',\n",
              "                                                           random_state=1,\n",
              "                                                           solver='lbfgs',\n",
              "                                                           tol=0.0001,\n",
              "                                                           verbose=0,\n",
              "                                                           warm_start=False))],\n",
              "                                verbose=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'logisticregression__C': [0.1, 1, 10]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='accuracy', verbose=0)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZ0InDB300re",
        "outputId": "c6ede467-830f-41af-c9e9-eac009b594ca"
      },
      "source": [
        "lGgrid.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.47557211595075266"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqKhD0onl6l5"
      },
      "source": [
        "### DesicionTree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b34tbDw4l9Cg"
      },
      "source": [
        "# Create Decision Tree classifer object\n",
        "dtc = DecisionTreeClassifier()\n",
        "\n",
        "dtcPipe = make_pipeline(full_pipeline,dtc)\n",
        "dtcPipe.fit(X_train_full,y_train)\n",
        "\n",
        "dtc_cross_val = cross_val_score(dtcPipe,X_train_full,y_train,cv=5,scoring='accuracy').mean()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b73vD82k62QZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce9ead4a-8a6d-4147-9e14-272178258cde"
      },
      "source": [
        "dtc_cross_val"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4252245880347075"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86J-a0eBl5lS"
      },
      "source": [
        "### RandomForest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfR6kH-iyHTy"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rfc = RandomForestClassifier(n_estimators=30, random_state=42)\n",
        "\n",
        "rfcPipe = make_pipeline(full_pipeline,rfc)\n",
        "rfcPipe.fit(X_train_full,y_train)\n",
        "\n",
        "rfc_cross_val = cross_val_score(rfcPipe,X_train_full,y_train,cv=5,scoring='accuracy').mean()\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUrp9YP-78y8"
      },
      "source": [
        "rfc_cross_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5Vfk2rDyLEG"
      },
      "source": [
        "predict = rfc.predict(X_valid_full)\n",
        "print(accuracy_score(y_valid, predict))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5FxtF6bnwmR"
      },
      "source": [
        "###KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvYNtdFT7OfL"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier(n_neighbors = 1)\n",
        "knn.fit(X_train_full, y_train)\n",
        "y_pred_knn = knn.predict(X_valid_full)\n",
        "print(accuracy_score(y_valid, y_pred_knn))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6VcYyvCyrav"
      },
      "source": [
        "# Numero de arboles\n",
        "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 80, num = 8)]\n",
        "# Numero de features considerado al dividir\n",
        "max_features = ['auto', 'sqrt']\n",
        "# numero maximo de niveles\n",
        "max_depth = [2,4]\n",
        "# Numero minimo de niveles por nodo\n",
        "min_samples_split = [2, 5]\n",
        "# Numero minimo de niveles por hoja\n",
        "min_samples_leaf = [1, 2]\n",
        "# metodo de seleccion por arbol \n",
        "bootstrap = [True, False]"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veu4QdkZn49l"
      },
      "source": [
        "### GridSerchCv RandonForest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wh1crlC3yuHh"
      },
      "source": [
        "#'randomforestclassifier__n_jobs': None\n",
        "#'randomforestclassifier__n_estimators': 30,\n",
        "params = {}\n",
        "\n",
        "params['logisticregression__C'] = [0.1,1,10]\n",
        "\n",
        "\n",
        "# Grilla\n",
        "param_grid = {}\n",
        "param_grid['randomforestclassifier__n_estimators'] = n_estimators\n",
        "param_grid['randomforestclassifier__max_features'] = max_features\n",
        "param_grid['randomforestclassifier__max_depth'] = max_depth\n",
        "param_grid['randomforestclassifier__min_samples_split'] = min_samples_split\n",
        "param_grid['randomforestclassifier__min_samples_leaf'] = min_samples_leaf = [1, 2]\n",
        "param_grid['randomforestclassifier__bootstrap'] = min_samples_leaf = bootstrap\n",
        "          \n",
        "          \n",
        "               #'bootstrap': bootstrap"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nDRxeJcyw7l"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "rfc_Grid = GridSearchCV(estimator = rfcPipe, param_grid = param_grid, cv = 3, scoring='accuracy')\n",
        "#, verbose=2, n_jobs = 4"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2G0dUgZyzVy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39f1529f-bb79-40fa-e03f-0e5d3419da90"
      },
      "source": [
        "rfc_Grid.fit(X_train_full, y_train)\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('columntransformer',\n",
              "                                        ColumnTransformer(n_jobs=None,\n",
              "                                                          remainder='drop',\n",
              "                                                          sparse_threshold=0.3,\n",
              "                                                          transformer_weights=None,\n",
              "                                                          transformers=[('numerical',\n",
              "                                                                         Pipeline(memory=None,\n",
              "                                                                                  steps=[('std_scaler',\n",
              "                                                                                          StandardScaler(copy=True,\n",
              "                                                                                                         with_mean=True,\n",
              "                                                                                                         with_std=True))],\n",
              "                                                                                  verbose=False),\n",
              "                                                                         ['popularity',\n",
              "                                                                          'acoustic...\n",
              "                         'randomforestclassifier__max_depth': [2, 4],\n",
              "                         'randomforestclassifier__max_features': ['auto',\n",
              "                                                                  'sqrt'],\n",
              "                         'randomforestclassifier__min_samples_leaf': [1, 2],\n",
              "                         'randomforestclassifier__min_samples_split': [2, 5],\n",
              "                         'randomforestclassifier__n_estimators': [10, 20, 30,\n",
              "                                                                  40, 50, 60,\n",
              "                                                                  70, 80]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='accuracy', verbose=0)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLJkqT6bf1sT",
        "outputId": "3263f91f-db55-4e8b-ec30-cd9c1a5920c9"
      },
      "source": [
        "rfcPipe.get_params()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'columntransformer': ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
              "                   transformer_weights=None,\n",
              "                   transformers=[('numerical',\n",
              "                                  Pipeline(memory=None,\n",
              "                                           steps=[('std_scaler',\n",
              "                                                   StandardScaler(copy=True,\n",
              "                                                                  with_mean=True,\n",
              "                                                                  with_std=True))],\n",
              "                                           verbose=False),\n",
              "                                  ['popularity', 'acousticness', 'danceability',\n",
              "                                   'duration_ms', 'energy', 'instrumentalness',\n",
              "                                   'liveness', 'loudness', 'speechiness',\n",
              "                                   'tempo', 'valence']),\n",
              "                                 ('cat',\n",
              "                                  OneHotEncoder(categories='auto', drop='first',\n",
              "                                                dtype=<class 'numpy.float64'>,\n",
              "                                                handle_unknown='error',\n",
              "                                                sparse=True),\n",
              "                                  ['key']),\n",
              "                                 ('cat1',\n",
              "                                  OrdinalEncoder(categories='auto',\n",
              "                                                 dtype=<class 'numpy.float64'>),\n",
              "                                  ['mode'])],\n",
              "                   verbose=False),\n",
              " 'columntransformer__cat': OneHotEncoder(categories='auto', drop='first', dtype=<class 'numpy.float64'>,\n",
              "               handle_unknown='error', sparse=True),\n",
              " 'columntransformer__cat1': OrdinalEncoder(categories='auto', dtype=<class 'numpy.float64'>),\n",
              " 'columntransformer__cat1__categories': 'auto',\n",
              " 'columntransformer__cat1__dtype': numpy.float64,\n",
              " 'columntransformer__cat__categories': 'auto',\n",
              " 'columntransformer__cat__drop': 'first',\n",
              " 'columntransformer__cat__dtype': numpy.float64,\n",
              " 'columntransformer__cat__handle_unknown': 'error',\n",
              " 'columntransformer__cat__sparse': True,\n",
              " 'columntransformer__n_jobs': None,\n",
              " 'columntransformer__numerical': Pipeline(memory=None,\n",
              "          steps=[('std_scaler',\n",
              "                  StandardScaler(copy=True, with_mean=True, with_std=True))],\n",
              "          verbose=False),\n",
              " 'columntransformer__numerical__memory': None,\n",
              " 'columntransformer__numerical__std_scaler': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              " 'columntransformer__numerical__std_scaler__copy': True,\n",
              " 'columntransformer__numerical__std_scaler__with_mean': True,\n",
              " 'columntransformer__numerical__std_scaler__with_std': True,\n",
              " 'columntransformer__numerical__steps': [('std_scaler',\n",
              "   StandardScaler(copy=True, with_mean=True, with_std=True))],\n",
              " 'columntransformer__numerical__verbose': False,\n",
              " 'columntransformer__remainder': 'drop',\n",
              " 'columntransformer__sparse_threshold': 0.3,\n",
              " 'columntransformer__transformer_weights': None,\n",
              " 'columntransformer__transformers': [('numerical', Pipeline(memory=None,\n",
              "            steps=[('std_scaler',\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True))],\n",
              "            verbose=False), ['popularity',\n",
              "    'acousticness',\n",
              "    'danceability',\n",
              "    'duration_ms',\n",
              "    'energy',\n",
              "    'instrumentalness',\n",
              "    'liveness',\n",
              "    'loudness',\n",
              "    'speechiness',\n",
              "    'tempo',\n",
              "    'valence']),\n",
              "  ('cat',\n",
              "   OneHotEncoder(categories='auto', drop='first', dtype=<class 'numpy.float64'>,\n",
              "                 handle_unknown='error', sparse=True),\n",
              "   ['key']),\n",
              "  ('cat1',\n",
              "   OrdinalEncoder(categories='auto', dtype=<class 'numpy.float64'>),\n",
              "   ['mode'])],\n",
              " 'columntransformer__verbose': False,\n",
              " 'memory': None,\n",
              " 'randomforestclassifier': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                        criterion='gini', max_depth=None, max_features='auto',\n",
              "                        max_leaf_nodes=None, max_samples=None,\n",
              "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                        min_samples_leaf=1, min_samples_split=2,\n",
              "                        min_weight_fraction_leaf=0.0, n_estimators=30,\n",
              "                        n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
              "                        warm_start=False),\n",
              " 'randomforestclassifier__bootstrap': True,\n",
              " 'randomforestclassifier__ccp_alpha': 0.0,\n",
              " 'randomforestclassifier__class_weight': None,\n",
              " 'randomforestclassifier__criterion': 'gini',\n",
              " 'randomforestclassifier__max_depth': None,\n",
              " 'randomforestclassifier__max_features': 'auto',\n",
              " 'randomforestclassifier__max_leaf_nodes': None,\n",
              " 'randomforestclassifier__max_samples': None,\n",
              " 'randomforestclassifier__min_impurity_decrease': 0.0,\n",
              " 'randomforestclassifier__min_impurity_split': None,\n",
              " 'randomforestclassifier__min_samples_leaf': 1,\n",
              " 'randomforestclassifier__min_samples_split': 2,\n",
              " 'randomforestclassifier__min_weight_fraction_leaf': 0.0,\n",
              " 'randomforestclassifier__n_estimators': 30,\n",
              " 'randomforestclassifier__n_jobs': None,\n",
              " 'randomforestclassifier__oob_score': False,\n",
              " 'randomforestclassifier__random_state': 42,\n",
              " 'randomforestclassifier__verbose': 0,\n",
              " 'randomforestclassifier__warm_start': False,\n",
              " 'steps': [('columntransformer',\n",
              "   ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
              "                     transformer_weights=None,\n",
              "                     transformers=[('numerical',\n",
              "                                    Pipeline(memory=None,\n",
              "                                             steps=[('std_scaler',\n",
              "                                                     StandardScaler(copy=True,\n",
              "                                                                    with_mean=True,\n",
              "                                                                    with_std=True))],\n",
              "                                             verbose=False),\n",
              "                                    ['popularity', 'acousticness', 'danceability',\n",
              "                                     'duration_ms', 'energy', 'instrumentalness',\n",
              "                                     'liveness', 'loudness', 'speechiness',\n",
              "                                     'tempo', 'valence']),\n",
              "                                   ('cat',\n",
              "                                    OneHotEncoder(categories='auto', drop='first',\n",
              "                                                  dtype=<class 'numpy.float64'>,\n",
              "                                                  handle_unknown='error',\n",
              "                                                  sparse=True),\n",
              "                                    ['key']),\n",
              "                                   ('cat1',\n",
              "                                    OrdinalEncoder(categories='auto',\n",
              "                                                   dtype=<class 'numpy.float64'>),\n",
              "                                    ['mode'])],\n",
              "                     verbose=False)),\n",
              "  ('randomforestclassifier',\n",
              "   RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                          criterion='gini', max_depth=None, max_features='auto',\n",
              "                          max_leaf_nodes=None, max_samples=None,\n",
              "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                          min_samples_leaf=1, min_samples_split=2,\n",
              "                          min_weight_fraction_leaf=0.0, n_estimators=30,\n",
              "                          n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
              "                          warm_start=False))],\n",
              " 'verbose': False}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gw5PnOrk7MSw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7aa3799-564e-487a-d671-d2338ba8aa77"
      },
      "source": [
        "rfc_Grid.best_score_"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4058617952323562"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfXqBtZRwa_p"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}